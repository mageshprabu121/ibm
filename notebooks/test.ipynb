{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# from pdf2image import convert_from_path\n",
    "# import pytesseract\n",
    "# from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "# from ibm_watson_machine_learning.foundation_models import Model\n",
    "# from ibm_watson_machine_learning.foundation_models.utils.enums import (\n",
    "#     DecodingMethods,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def parse_pdf_pytesseract(pdf_path, page_number=0) -> str:\n",
    "    images = convert_from_path(\n",
    "        pdf_path, first_page=page_number + 1, last_page=page_number + 1\n",
    "    )\n",
    "    if not images:\n",
    "        return \"Failed to convert PDF to image\"\n",
    "    page_image = images[0]\n",
    "    extracted_text = pytesseract.image_to_string(page_image)\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize the model\n",
    "def initialize_model(model_id):\n",
    "    generate_params = {\n",
    "        GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "        GenParams.MAX_NEW_TOKENS: 1024,\n",
    "    }\n",
    "    model = Model(\n",
    "        model_id=model_id,\n",
    "        params=generate_params,\n",
    "        credentials={\"apikey\": os.getenv(\"GA_API_KEY\"), \"url\": os.getenv(\"GA_URL\")},\n",
    "        project_id=os.getenv(\"GA_PROJECT_ID\"),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract resume information\n",
    "def resume_extraction(parsed_pdf_file, model_id, prompt):\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\"), \"w\") as file:\n",
    "        file.write(parse_pdf_pytesseract(parsed_pdf_file, 0))\n",
    "\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\")) as file:\n",
    "        text = file.read()\n",
    "\n",
    "    parsed_pdf_file = os.path.basename(parsed_pdf_file)\n",
    "    text += \"\\n\" + \"File Name: \" + parsed_pdf_file + \"\\n\"\n",
    "    # print(\"text: \", text)\n",
    "    prompt = prompt.format(filename=parsed_pdf_file, text=text)\n",
    "\n",
    "    with open(\"r_prompt.txt\", \"w\") as file:\n",
    "        file.write(prompt)\n",
    "\n",
    "    input_tokens = 0\n",
    "    input_tokens += len(prompt)\n",
    "\n",
    "    model = initialize_model(model_id)\n",
    "    inferred = []\n",
    "    output_tokens = 0\n",
    "\n",
    "    resp = model.generate(prompt=prompt)[\"results\"][0][\"generated_text\"]\n",
    "    output_tokens += len(resp)\n",
    "\n",
    "    try:\n",
    "        first, last = resp.find(\"{\"), resp.rfind(\"}\")\n",
    "        resp = json.loads(resp[first : last + 1], strict=False)\n",
    "        inferred.append(resp)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Invalid JSON:\", e)\n",
    "\n",
    "    return input_tokens, output_tokens, inferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample usage\n",
    "pdf_path = \"/Users/charan/VS_Code/EMEA/db-schenker-entity-extraction/src/entity_extraction/Charana_H_U_Resume_2024.pdf\"\n",
    "model_id = \"meta-llama/llama-3-70b-instruct\"\n",
    "resume_extraction_prompt_input = \"\"\"[INST] You are an information extraction assistant. Your task is to extract the following information in JSON format:\n",
    "- Name: \"name\"\n",
    "- Email: \"email\"\n",
    "- Phone Number: \"phone_number\"\n",
    "- Current Organization: \"current_organization\"\n",
    "- Years of Experience: \"years_experience\"\n",
    "- Skills: \"skills\"\n",
    "\n",
    "Use this syntax for your response:\n",
    "{{\n",
    "    \"filename\": {filename},\n",
    "    \"name\": \"...\",\n",
    "    \"email\": \"...\",\n",
    "    \"phone_number\": \"...\",\n",
    "    \"current_organization\": \"...\",\n",
    "    \"years_experience\": \"...\",\n",
    "    \"skills\": \"...\"\n",
    "}}\n",
    "\n",
    "\n",
    "Input: {text}\n",
    "\n",
    "Output:\"\"\"\n",
    "\n",
    "# Extract information from the resume\n",
    "input_tokens, output_tokens, inferred = resume_extraction(\n",
    "    pdf_path, model_id, resume_extraction_prompt_input\n",
    ")\n",
    "print(\"Input Tokens:\", input_tokens)\n",
    "print(\"Output Tokens:\", output_tokens)\n",
    "print(\"Inferred Information:\", inferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import (\n",
    "    DecodingMethods,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def parse_pdf_pytesseract(pdf_path, page_number=0) -> str:\n",
    "    images = convert_from_path(\n",
    "        pdf_path, first_page=page_number + 1, last_page=page_number + 1\n",
    "    )\n",
    "    if not images:\n",
    "        return \"Failed to convert PDF to image\"\n",
    "    page_image = images[0]\n",
    "    extracted_text = pytesseract.image_to_string(page_image)\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# Function to initialize the model\n",
    "def initialize_model(model_id):\n",
    "    generate_params = {\n",
    "        GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "        GenParams.MAX_NEW_TOKENS: 1024,\n",
    "    }\n",
    "    model = Model(\n",
    "        model_id=model_id,\n",
    "        params=generate_params,\n",
    "        credentials={\"apikey\": os.getenv(\"GA_API_KEY\"), \"url\": os.getenv(\"GA_URL\")},\n",
    "        project_id=os.getenv(\"GA_PROJECT_ID\"),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to extract resume information and insert into SQLite\n",
    "def resume_extraction_and_insert(parsed_pdf_file, model_id, prompt, db_path):\n",
    "    # Extract text from PDF\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\"), \"w\") as file:\n",
    "        file.write(parse_pdf_pytesseract(parsed_pdf_file, 0))\n",
    "\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\")) as file:\n",
    "        text = file.read()\n",
    "\n",
    "    parsed_pdf_file = os.path.basename(parsed_pdf_file)\n",
    "    text += \"\\n\" + \"File Name: \" + parsed_pdf_file + \"\\n\"\n",
    "    prompt = prompt.format(filename=parsed_pdf_file, text=text)\n",
    "\n",
    "    with open(\"r_prompt.txt\", \"w\") as file:\n",
    "        file.write(prompt)\n",
    "\n",
    "    # Initialize Watsonx model\n",
    "    model = initialize_model(model_id)\n",
    "\n",
    "    # Generate response\n",
    "    resp = model.generate(prompt=prompt)[\"results\"][0][\"generated_text\"]\n",
    "\n",
    "    try:\n",
    "        # Extract JSON from response\n",
    "        first, last = resp.find(\"{\"), resp.rfind(\"}\")\n",
    "        resp_json = json.loads(resp[first : last + 1], strict=False)\n",
    "\n",
    "        # Extract information from JSON\n",
    "        name = resp_json.get(\"name\", \"\")\n",
    "        email = resp_json.get(\"email\", \"\")\n",
    "        phone_number = resp_json.get(\"phone_number\", \"\")\n",
    "        current_organization = resp_json.get(\"current_organization\", \"\")\n",
    "        years_experience = resp_json.get(\"years_experience\", \"\")\n",
    "        skills = resp_json.get(\"skills\", \"\")\n",
    "\n",
    "        # Insert into SQLite database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        c = conn.cursor()\n",
    "\n",
    "        # Create table if not exists\n",
    "        c.execute(\n",
    "            \"\"\"CREATE TABLE IF NOT EXISTS resumes\n",
    "                     (name TEXT, email TEXT, phone_number TEXT,\n",
    "                      current_organization TEXT, years_experience TEXT, skills TEXT)\"\"\"\n",
    "        )\n",
    "\n",
    "        # Insert extracted data into the table\n",
    "        c.execute(\n",
    "            \"INSERT INTO resumes VALUES (?, ?, ?, ?, ?, ?)\",\n",
    "            (name, email, phone_number, current_organization, years_experience, skills),\n",
    "        )\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "        inferred = {\n",
    "            \"name\": name,\n",
    "            \"email\": email,\n",
    "            \"phone_number\": phone_number,\n",
    "            \"current_organization\": current_organization,\n",
    "            \"years_experience\": years_experience,\n",
    "            \"skills\": skills,\n",
    "        }\n",
    "\n",
    "        return inferred\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Invalid JSON:\", e)\n",
    "        return 0, 0, {}\n",
    "\n",
    "\n",
    "# Sample usage\n",
    "pdf_path = \"/Users/charan/VS_Code/EMEA/db-schenker-entity-extraction/src/entity_extraction/s-2.pdf\"\n",
    "model_id = \"meta-llama/llama-3-70b-instruct\"\n",
    "resume_extraction_prompt_input = \"\"\"[INST] You are an information extraction assistant. Your task is to extract the following information in JSON format:\n",
    "- Name: \"name\"\n",
    "- Email: \"email\"\n",
    "- Phone Number: \"phone_number\"\n",
    "- Current Organization: \"current_organization\"\n",
    "- Years of Experience: \"years_experience\"\n",
    "- Skills: \"skills\"\n",
    "\n",
    "Use this syntax for your response:\n",
    "{{\n",
    "    \"filename\": {filename},\n",
    "    \"name\": \"...\",\n",
    "    \"email\": \"...\",\n",
    "    \"phone_number\": \"...\",\n",
    "    \"current_organization\": \"...\",\n",
    "    \"years_experience\": \"...\",\n",
    "    \"skills\": \"...\"\n",
    "}}\n",
    "\n",
    "\n",
    "Input: {text}\n",
    "\n",
    "Output:\"\"\"\n",
    "\n",
    "db_path = \"resume_data.db\"\n",
    "\n",
    "# Extract information from the resume and insert into SQLite\n",
    "inferred = resume_extraction_and_insert(\n",
    "    pdf_path, model_id, resume_extraction_prompt_input, db_path\n",
    ")\n",
    "print(\"Inferred Information:\", inferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import (\n",
    "    DecodingMethods,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def parse_pdf_pytesseract(pdf_path, page_number=0) -> str:\n",
    "    images = convert_from_path(\n",
    "        pdf_path, first_page=page_number + 1, last_page=page_number + 1\n",
    "    )\n",
    "    if not images:\n",
    "        return \"Failed to convert PDF to image\"\n",
    "    page_image = images[0]\n",
    "    extracted_text = pytesseract.image_to_string(page_image)\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# Function to initialize the model\n",
    "def initialize_model(model_id):\n",
    "    generate_params = {\n",
    "        GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "        GenParams.MAX_NEW_TOKENS: 1024,\n",
    "    }\n",
    "    model = Model(\n",
    "        model_id=model_id,\n",
    "        params=generate_params,\n",
    "        credentials={\"apikey\": os.getenv(\"GA_API_KEY\"), \"url\": os.getenv(\"GA_URL\")},\n",
    "        project_id=os.getenv(\"GA_PROJECT_ID\"),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to check if email exists in SQLite database\n",
    "def check_email_exists(conn, email):\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT COUNT(*) FROM resumes WHERE email=?\", (email,))\n",
    "    result = c.fetchone()\n",
    "    return result[0] > 0\n",
    "\n",
    "\n",
    "# Function to insert or update resume information in SQLite\n",
    "def resume_extraction_and_insert(parsed_pdf_file, model_id, prompt, db_path):\n",
    "    # Extract text from PDF\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\"), \"w\") as file:\n",
    "        file.write(parse_pdf_pytesseract(parsed_pdf_file, 0))\n",
    "\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\")) as file:\n",
    "        text = file.read()\n",
    "\n",
    "    parsed_pdf_file = os.path.basename(parsed_pdf_file)\n",
    "    text += \"\\n\" + \"File Name: \" + parsed_pdf_file + \"\\n\"\n",
    "    prompt = prompt.format(filename=parsed_pdf_file, text=text)\n",
    "\n",
    "    with open(\"r_prompt.txt\", \"w\") as file:\n",
    "        file.write(prompt)\n",
    "\n",
    "    # Initialize Watsonx model\n",
    "    model = initialize_model(model_id)\n",
    "\n",
    "    # Generate response\n",
    "    resp = model.generate(prompt=prompt)[\"results\"][0][\"generated_text\"]\n",
    "\n",
    "    try:\n",
    "        # Extract JSON from response\n",
    "        first, last = resp.find(\"{\"), resp.rfind(\"}\")\n",
    "        resp_json = json.loads(resp[first : last + 1], strict=False)\n",
    "\n",
    "        # Extract information from JSON\n",
    "        name = resp_json.get(\"name\", \"\")\n",
    "        email = resp_json.get(\"email\", \"\")\n",
    "        phone_number = resp_json.get(\"phone_number\", \"\")\n",
    "        current_organization = resp_json.get(\"current_organization\", \"\")\n",
    "        years_experience = resp_json.get(\"years_experience\", \"\")\n",
    "        skills = resp_json.get(\"skills\", \"\")\n",
    "\n",
    "        # Connect to SQLite database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "\n",
    "        # Check if email already exists\n",
    "        if check_email_exists(conn, email):\n",
    "            # Perform update if email exists\n",
    "            c = conn.cursor()\n",
    "            c.execute(\n",
    "                \"\"\"UPDATE resumes \n",
    "                         SET name=?, phone_number=?, current_organization=?, \n",
    "                             years_experience=?, skills=?\n",
    "                         WHERE email=?\"\"\",\n",
    "                (\n",
    "                    name,\n",
    "                    phone_number,\n",
    "                    current_organization,\n",
    "                    years_experience,\n",
    "                    skills,\n",
    "                    email,\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            # Perform insert if email does not exist\n",
    "            c = conn.cursor()\n",
    "            c.execute(\n",
    "                \"\"\"INSERT INTO resumes \n",
    "                         (name, email, phone_number, current_organization, years_experience, skills) \n",
    "                         VALUES (?, ?, ?, ?, ?, ?)\"\"\",\n",
    "                (\n",
    "                    name,\n",
    "                    email,\n",
    "                    phone_number,\n",
    "                    current_organization,\n",
    "                    years_experience,\n",
    "                    skills,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "        inferred = {\n",
    "            \"name\": name,\n",
    "            \"email\": email,\n",
    "            \"phone_number\": phone_number,\n",
    "            \"current_organization\": current_organization,\n",
    "            \"years_experience\": years_experience,\n",
    "            \"skills\": skills,\n",
    "        }\n",
    "\n",
    "        return inferred\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Invalid JSON:\", e)\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Sample usage\n",
    "pdf_path = \"/Users/charan/VS_Code/EMEA/db-schenker-entity-extraction/src/entity_extraction/s-2.pdf\"\n",
    "model_id = \"meta-llama/llama-3-70b-instruct\"\n",
    "resume_extraction_prompt_input = \"\"\"[INST] You are an information extraction assistant. Your task is to extract the following information in JSON format:\n",
    "- Name: \"name\"\n",
    "- Email: \"email\"\n",
    "- Phone Number: \"phone_number\"\n",
    "- Current Organization: \"current_organization\"\n",
    "- Years of Experience: \"years_experience\"\n",
    "- Skills: \"skills\"\n",
    "\n",
    "Use this syntax for your response:\n",
    "{{\n",
    "    \"filename\": {filename},\n",
    "    \"name\": \"...\",\n",
    "    \"email\": \"...\",\n",
    "    \"phone_number\": \"...\",\n",
    "    \"current_organization\": \"...\",\n",
    "    \"years_experience\": \"...\",\n",
    "    \"skills\": \"...\"\n",
    "}}\n",
    "\n",
    "\n",
    "Input: {text}\n",
    "\n",
    "Output:\"\"\"\n",
    "\n",
    "db_path = \"resume_data.db\"\n",
    "\n",
    "# Extract information from the resume and insert or update into SQLite\n",
    "inferred = resume_extraction_and_insert(\n",
    "    pdf_path, model_id, resume_extraction_prompt_input, db_path\n",
    ")\n",
    "print(\"Inferred Information:\", inferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import (\n",
    "    DecodingMethods,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def parse_pdf_pytesseract(pdf_path, page_number=0) -> str:\n",
    "    images = convert_from_path(\n",
    "        pdf_path, first_page=page_number + 1, last_page=page_number + 1\n",
    "    )\n",
    "    if not images:\n",
    "        return \"Failed to convert PDF to image\"\n",
    "    page_image = images[0]\n",
    "    extracted_text = pytesseract.image_to_string(page_image)\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# Function to initialize the model\n",
    "def initialize_model(model_id):\n",
    "    generate_params = {\n",
    "        GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "        GenParams.MAX_NEW_TOKENS: 1024,\n",
    "    }\n",
    "    model = Model(\n",
    "        model_id=model_id,\n",
    "        params=generate_params,\n",
    "        credentials={\"apikey\": os.getenv(\"GA_API_KEY\"), \"url\": os.getenv(\"GA_URL\")},\n",
    "        project_id=os.getenv(\"GA_PROJECT_ID\"),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to check if email exists in SQLite database\n",
    "def check_email_exists(conn, email):\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT COUNT(*) FROM resumes WHERE email=?\", (email,))\n",
    "    result = c.fetchone()\n",
    "    return result[0] > 0\n",
    "\n",
    "\n",
    "# Function to insert or update resume information in SQLite\n",
    "def resume_extraction_and_insert(parsed_pdf_file, model_id, prompt, db_path):\n",
    "    # Extract text from PDF\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\"), \"w\") as file:\n",
    "        file.write(parse_pdf_pytesseract(parsed_pdf_file, 0))\n",
    "\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\")) as file:\n",
    "        text = file.read()\n",
    "\n",
    "    parsed_pdf_file = os.path.basename(parsed_pdf_file)\n",
    "    text += \"\\n\" + \"File Name: \" + parsed_pdf_file + \"\\n\"\n",
    "    prompt = prompt.format(filename=parsed_pdf_file, text=text)\n",
    "\n",
    "    with open(\"r_prompt.txt\", \"w\") as file:\n",
    "        file.write(prompt)\n",
    "\n",
    "    # Initialize Watsonx model\n",
    "    model = initialize_model(model_id)\n",
    "\n",
    "    # Generate response\n",
    "    resp = model.generate(prompt=prompt)[\"results\"][0][\"generated_text\"]\n",
    "\n",
    "    try:\n",
    "        # Extract JSON from response\n",
    "        first, last = resp.find(\"{\"), resp.rfind(\"}\")\n",
    "        resp_json = json.loads(resp[first : last + 1], strict=False)\n",
    "\n",
    "        # Extract information from JSON\n",
    "        name = resp_json.get(\"name\", \"\")\n",
    "        email = resp_json.get(\"email\", \"\")\n",
    "        phone_number = resp_json.get(\"phone_number\", \"\")\n",
    "        current_organization = resp_json.get(\"current_organization\", \"\")\n",
    "        years_experience = resp_json.get(\"years_experience\", \"\")\n",
    "        skills = resp_json.get(\"skills\", \"\")\n",
    "\n",
    "        # Connect to SQLite database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "\n",
    "        # Check if email already exists\n",
    "        if check_email_exists(conn, email):\n",
    "            # Perform update if email exists\n",
    "            c = conn.cursor()\n",
    "            c.execute(\n",
    "                \"\"\"UPDATE resumes \n",
    "                         SET name=?, phone_number=?, current_organization=?, \n",
    "                             years_experience=?, skills=?\n",
    "                         WHERE email=?\"\"\",\n",
    "                (\n",
    "                    name,\n",
    "                    phone_number,\n",
    "                    current_organization,\n",
    "                    years_experience,\n",
    "                    skills,\n",
    "                    email,\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            # Perform insert if email does not exist\n",
    "            c = conn.cursor()\n",
    "            c.execute(\n",
    "                \"\"\"INSERT INTO resumes \n",
    "                         (name, email, phone_number, current_organization, years_experience, skills) \n",
    "                         VALUES (?, ?, ?, ?, ?, ?)\"\"\",\n",
    "                (\n",
    "                    name,\n",
    "                    email,\n",
    "                    phone_number,\n",
    "                    current_organization,\n",
    "                    years_experience,\n",
    "                    skills,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "        inferred = {\n",
    "            \"name\": name,\n",
    "            \"email\": email,\n",
    "            \"phone_number\": phone_number,\n",
    "            \"current_organization\": current_organization,\n",
    "            \"years_experience\": years_experience,\n",
    "            \"skills\": skills,\n",
    "        }\n",
    "\n",
    "        return inferred\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Invalid JSON:\", e)\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Function to process multiple PDFs\n",
    "def process_multiple_pdfs(pdf_paths, model_id, prompt, db_path):\n",
    "    results = []\n",
    "    for pdf_path in pdf_paths:\n",
    "        inferred = resume_extraction_and_insert(pdf_path, model_id, prompt, db_path)\n",
    "        results.append(inferred)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Sample usage\n",
    "pdf_paths = [\n",
    "    \"/Users/charan/VS_Code/EMEA/db-schenker-entity-extraction/src/entity_extraction/Charana_H_U_Resume_2024.pdf\",\n",
    "    \"/Users/charan/VS_Code/EMEA/db-schenker-entity-extraction/src/entity_extraction/s-2.pdf\",\n",
    "]\n",
    "model_id = \"meta-llama/llama-3-70b-instruct\"\n",
    "resume_extraction_prompt_input = \"\"\"[INST] You are an information extraction assistant. Your task is to extract the following information in JSON format:\n",
    "- Name: \"name\"\n",
    "- Email: \"email\"\n",
    "- Phone Number: \"phone_number\"\n",
    "- Current Organization: \"current_organization\"\n",
    "- Years of Experience: \"years_experience\"\n",
    "- Skills: \"skills\"\n",
    "\n",
    "Use this syntax for your response:\n",
    "{{\n",
    "    \"filename\": {filename},\n",
    "    \"name\": \"...\",\n",
    "    \"email\": \"...\",\n",
    "    \"phone_number\": \"...\",\n",
    "    \"current_organization\": \"...\",\n",
    "    \"years_experience\": \"...\",\n",
    "    \"skills\": \"...\"\n",
    "}}\n",
    "\n",
    "\n",
    "Input: {text}\n",
    "\n",
    "Output:\"\"\"\n",
    "\n",
    "db_path = \"resume_data.db\"\n",
    "\n",
    "# Process multiple PDFs and insert or update into SQLite\n",
    "results = process_multiple_pdfs(\n",
    "    pdf_paths, model_id, resume_extraction_prompt_input, db_path\n",
    ")\n",
    "print(\"Inferred Information for all PDFs:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred Information for all PDFs: [{'name': 'Charana H U', 'email': 'charanhumail@gmail.com', 'phone_number': '+91 9481368353', 'current_organization': 'IBM (India Pvt. Ltd,)', 'years_experience': '2.5+ years', 'skills': 'Python, Langchain, Llama-Index, Django, Flask, ChromaDB, Milvus, Weaviate, MySQL, SQL Lite, Microsoft SQL Server, PyCharm, Visual Studio, VS Code, AWS Bedrock, AWS Sagemaker, Azure ML, Google Vertex Al, Watsonx.ai, NumPy, Pandas, Matplotlib, SciPy, Skit-learn, OpenCv, Tensor Flow, Keras, Pytorch, Prompt Engineering, LLM-Finetuning, Embedding Model Fine-tuning, OpenAl Whisper Speech to Text, Attention, Transformers, BERT, MLP, CNN, RNN, LSTM, Encoders and Decoders, Seq2Seq, GANs, YOLO, Docker, Git/GitHub, Elevator pitch, Stand and deliver, Public Speaking, Leadership, Teamwork and Presentation'}, {'name': 'Sohan M', 'email': 'sohanm10@gmail.com', 'phone_number': '8050636614', 'current_organization': 'IBM Bengaluru, India', 'years_experience': 'Not mentioned', 'skills': 'Python, NumPy, Pandas, Matplotlib, Skit-learn, ChromaDB, Milvus, Weaviate, MySQL, LangChain, Llamalndex, TensorFlow, PyTorch, Streamlight, Flask, OpenAl, Google Gemini Pro, Naive Bayes, Logistic Regression, Linear Regression, SVMs, Decision Tree, Analytical thinking, Problem-solving, Teamwork, Effective communication'}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import (\n",
    "    DecodingMethods,\n",
    ")\n",
    "\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def parse_pdf_pytesseract(pdf_path, page_number=0) -> str:\n",
    "    images = convert_from_path(\n",
    "        pdf_path, first_page=page_number + 1, last_page=page_number + 1\n",
    "    )\n",
    "    if not images:\n",
    "        return \"Failed to convert PDF to image\"\n",
    "    page_image = images[0]\n",
    "    extracted_text = pytesseract.image_to_string(page_image)\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# Function to initialize the model\n",
    "def initialize_model(model_id):\n",
    "    generate_params = {\n",
    "        GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "        GenParams.MAX_NEW_TOKENS: 1024,\n",
    "    }\n",
    "    model = Model(\n",
    "        model_id=model_id,\n",
    "        params=generate_params,\n",
    "        credentials={\"apikey\": os.getenv(\"GA_API_KEY\"), \"url\": os.getenv(\"GA_URL\")},\n",
    "        project_id=os.getenv(\"GA_PROJECT_ID\"),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to check if email exists in SQLite database\n",
    "def check_email_exists(conn, email):\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT COUNT(*) FROM resumes WHERE email=?\", (email,))\n",
    "    result = c.fetchone()\n",
    "    return result[0] > 0\n",
    "\n",
    "\n",
    "# Function to create resumes table if not exists\n",
    "def create_resumes_table(conn):\n",
    "    c = conn.cursor()\n",
    "    c.execute(\n",
    "        \"\"\"CREATE TABLE IF NOT EXISTS resumes\n",
    "                 (name TEXT, email TEXT PRIMARY KEY, phone_number TEXT,\n",
    "                  current_organization TEXT, years_experience TEXT, skills TEXT)\"\"\"\n",
    "    )\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "# Function to insert or update resume information in SQLite\n",
    "def resume_extraction_and_insert(parsed_pdf_file, model_id, prompt, db_path):\n",
    "    # Extract text from PDF\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\"), \"w\") as file:\n",
    "        file.write(parse_pdf_pytesseract(parsed_pdf_file, 0))\n",
    "\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\")) as file:\n",
    "        text = file.read()\n",
    "\n",
    "    parsed_pdf_file = os.path.basename(parsed_pdf_file)\n",
    "    text += \"\\n\" + \"File Name: \" + parsed_pdf_file + \"\\n\"\n",
    "    prompt = prompt.format(filename=parsed_pdf_file, text=text)\n",
    "\n",
    "    with open(\"r_prompt.txt\", \"w\") as file:\n",
    "        file.write(prompt)\n",
    "\n",
    "    # Initialize Watsonx model\n",
    "    model = initialize_model(model_id)\n",
    "\n",
    "    # Generate response\n",
    "    resp = model.generate(prompt=prompt)[\"results\"][0][\"generated_text\"]\n",
    "\n",
    "    try:\n",
    "        # Extract JSON from response\n",
    "        first, last = resp.find(\"{\"), resp.rfind(\"}\")\n",
    "        resp_json = json.loads(resp[first : last + 1], strict=False)\n",
    "\n",
    "        # Extract information from JSON\n",
    "        name = resp_json.get(\"name\", \"\")\n",
    "        email = resp_json.get(\"email\", \"\")\n",
    "        phone_number = resp_json.get(\"phone_number\", \"\")\n",
    "        current_organization = resp_json.get(\"current_organization\", \"\")\n",
    "        years_experience = resp_json.get(\"years_experience\", \"\")\n",
    "        skills = resp_json.get(\"skills\", \"\")\n",
    "\n",
    "        # Connect to SQLite database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "\n",
    "        # Ensure resumes table exists\n",
    "        create_resumes_table(conn)\n",
    "\n",
    "        # Check if email already exists\n",
    "        if check_email_exists(conn, email):\n",
    "            # Perform update if email exists\n",
    "            c = conn.cursor()\n",
    "            c.execute(\n",
    "                \"\"\"UPDATE resumes \n",
    "                         SET name=?, phone_number=?, current_organization=?, \n",
    "                             years_experience=?, skills=?\n",
    "                         WHERE email=?\"\"\",\n",
    "                (\n",
    "                    name,\n",
    "                    phone_number,\n",
    "                    current_organization,\n",
    "                    years_experience,\n",
    "                    skills,\n",
    "                    email,\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            # Perform insert if email does not exist\n",
    "            c = conn.cursor()\n",
    "            c.execute(\n",
    "                \"\"\"INSERT INTO resumes \n",
    "                         (name, email, phone_number, current_organization, years_experience, skills) \n",
    "                         VALUES (?, ?, ?, ?, ?, ?)\"\"\",\n",
    "                (\n",
    "                    name,\n",
    "                    email,\n",
    "                    phone_number,\n",
    "                    current_organization,\n",
    "                    years_experience,\n",
    "                    skills,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "        inferred = {\n",
    "            \"name\": name,\n",
    "            \"email\": email,\n",
    "            \"phone_number\": phone_number,\n",
    "            \"current_organization\": current_organization,\n",
    "            \"years_experience\": years_experience,\n",
    "            \"skills\": skills,\n",
    "        }\n",
    "\n",
    "        return inferred\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Invalid JSON:\", e)\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Function to process multiple PDFs\n",
    "def process_multiple_pdfs(pdf_paths, model_id, prompt, db_path):\n",
    "    results = []\n",
    "    for pdf_path in pdf_paths:\n",
    "        inferred = resume_extraction_and_insert(pdf_path, model_id, prompt, db_path)\n",
    "        results.append(inferred)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Sample usage\n",
    "pdf_paths = [\n",
    "    \"/Users/charan/VS_Code/EMEA/db-schenker-entity-extraction/src/entity_extraction/Charana_H_U_Resume_2024.pdf\",\n",
    "    \"/Users/charan/VS_Code/EMEA/db-schenker-entity-extraction/src/entity_extraction/s-2.pdf\",\n",
    "]\n",
    "model_id = \"meta-llama/llama-3-70b-instruct\"\n",
    "resume_extraction_prompt_input = \"\"\"You are an information extraction assistant. Your task is to extract the following information in JSON format:\n",
    "- Name: \"name\"\n",
    "- Email: \"email\"\n",
    "- Phone Number: \"phone_number\"\n",
    "- Current Organization: \"current_organization\"\n",
    "- Years of Experience: \"years_experience\"\n",
    "- Skills: \"skills\"\n",
    "\n",
    "Use this syntax for your response:\n",
    "{{\n",
    "    \"filename\": {filename},\n",
    "    \"name\": \"...\",\n",
    "    \"email\": \"...\",\n",
    "    \"phone_number\": \"...\",\n",
    "    \"current_organization\": \"...\",\n",
    "    \"years_experience\": \"...\",\n",
    "    \"skills\": \"...\"\n",
    "}}\n",
    "\n",
    "\n",
    "Input: {text}\n",
    "\n",
    "Output:\"\"\"\n",
    "\n",
    "db_path = \"resume_data.db\"\n",
    "\n",
    "# Process multiple PDFs and insert or update into SQLite\n",
    "results = process_multiple_pdfs(\n",
    "    pdf_paths, model_id, resume_extraction_prompt_input, db_path\n",
    ")\n",
    "print(\"Inferred Information for all PDFs:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred Information for all PDFs: [{'name': 'Sohan M', 'email': 'sohanm10@gmail.com', 'phone_number': '8050636614', 'current_organization': 'IBM Bengaluru, India', 'years_experience': 'Not mentioned', 'skills': 'Python, NumPy, Pandas, Matplotlib, Skit-learn, ChromaDB, Milvus, Weaviate, MySQL, LangChain, Llamalndex, TensorFlow, PyTorch, Streamlight, Flask, OpenAl, Google Gemini Pro, Naive Bayes, Logistic Regression, Linear Regression, SVMs, Decision Tree, Analytical thinking, Problem-solving, Teamwork, Effective communication'}, {'name': 'Charana H U', 'email': 'charanhumail@gmail.com', 'phone_number': '+91 9481368353', 'current_organization': 'IBM (India Pvt. Ltd,)', 'years_experience': '2.5+ years', 'skills': 'Python, Langchain, Llama-Index, Django, Flask, ChromaDB, Milvus, Weaviate, MySQL, SQL Lite, Microsoft SQL Server, PyCharm, Visual Studio, VS Code, AWS Bedrock, AWS Sagemaker, Azure ML, Google Vertex Al, Watsonx.ai, NumPy, Pandas, Matplotlib, SciPy, Skit-learn, OpenCv, Tensor Flow, Keras, Pytorch, Prompt Engineering, LLM-Finetuning, Embedding Model Fine-tuning, OpenAl Whisper Speech to Text, Attention, Transformers, BERT, MLP, CNN, RNN, LSTM, Encoders and Decoders, Seq2Seq, GANs, YOLO, Docker, Git/GitHub, Elevator pitch, Stand and deliver, Public Speaking, Leadership, Teamwork and Presentation'}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import (\n",
    "    DecodingMethods,\n",
    ")\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def parse_pdf_pytesseract(pdf_path, page_number=0) -> str:\n",
    "    images = convert_from_path(\n",
    "        pdf_path, first_page=page_number + 1, last_page=page_number + 1\n",
    "    )\n",
    "    if not images:\n",
    "        return \"Failed to convert PDF to image\"\n",
    "    page_image = images[0]\n",
    "    extracted_text = pytesseract.image_to_string(page_image)\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# Function to initialize the model\n",
    "def initialize_model(model_id):\n",
    "    generate_params = {\n",
    "        GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "        GenParams.MAX_NEW_TOKENS: 1024,\n",
    "    }\n",
    "    model = Model(\n",
    "        model_id=model_id,\n",
    "        params=generate_params,\n",
    "        credentials={\"apikey\": os.getenv(\"GA_API_KEY\"), \"url\": os.getenv(\"GA_URL\")},\n",
    "        project_id=os.getenv(\"GA_PROJECT_ID\"),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to check if email exists in SQLite database\n",
    "def check_email_exists(conn, email):\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT COUNT(*) FROM resumes WHERE email=?\", (email,))\n",
    "    result = c.fetchone()\n",
    "    return result[0] > 0\n",
    "\n",
    "\n",
    "# Function to create resumes table if not exists\n",
    "def create_resumes_table(conn):\n",
    "    c = conn.cursor()\n",
    "    c.execute(\n",
    "        \"\"\"CREATE TABLE IF NOT EXISTS resumes\n",
    "                 (name TEXT, email TEXT PRIMARY KEY, phone_number TEXT,\n",
    "                  current_organization TEXT, years_experience TEXT, skills TEXT)\"\"\"\n",
    "    )\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "# Function to insert or update resume information in SQLite\n",
    "def resume_extraction_and_insert(parsed_pdf_file, model_id, prompt, db_path):\n",
    "    # Extract text from PDF\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\"), \"w\") as file:\n",
    "        file.write(parse_pdf_pytesseract(parsed_pdf_file, 0))\n",
    "\n",
    "    with open(parsed_pdf_file.replace(\".pdf\", \".txt\")) as file:\n",
    "        text = file.read()\n",
    "\n",
    "    parsed_pdf_file = os.path.basename(parsed_pdf_file)\n",
    "    text += \"\\n\" + \"File Name: \" + parsed_pdf_file + \"\\n\"\n",
    "    prompt = prompt.format(filename=parsed_pdf_file, text=text)\n",
    "\n",
    "    with open(\"r_prompt.txt\", \"w\") as file:\n",
    "        file.write(prompt)\n",
    "\n",
    "    # Initialize Watsonx model\n",
    "    model = initialize_model(model_id)\n",
    "\n",
    "    # Generate response\n",
    "    resp = model.generate(prompt=prompt)[\"results\"][0][\"generated_text\"]\n",
    "\n",
    "    try:\n",
    "        # Extract JSON from response\n",
    "        first, last = resp.find(\"{\"), resp.rfind(\"}\")\n",
    "        resp_json = json.loads(resp[first : last + 1], strict=False)\n",
    "\n",
    "        # Extract information from JSON\n",
    "        name = resp_json.get(\"name\", \"\")\n",
    "        email = resp_json.get(\"email\", \"\")\n",
    "        phone_number = resp_json.get(\"phone_number\", \"\")\n",
    "        current_organization = resp_json.get(\"current_organization\", \"\")\n",
    "        years_experience = resp_json.get(\"years_experience\", \"\")\n",
    "        skills = resp_json.get(\"skills\", \"\")\n",
    "\n",
    "        # Connect to SQLite database\n",
    "        conn = sqlite3.connect(db_path)\n",
    "\n",
    "        # Ensure resumes table exists\n",
    "        create_resumes_table(conn)\n",
    "\n",
    "        # Check if email already exists\n",
    "        if check_email_exists(conn, email):\n",
    "            # Perform update if email exists\n",
    "            c = conn.cursor()\n",
    "            c.execute(\n",
    "                \"\"\"UPDATE resumes \n",
    "                         SET name=?, phone_number=?, current_organization=?, \n",
    "                             years_experience=?, skills=?\n",
    "                         WHERE email=?\"\"\",\n",
    "                (\n",
    "                    name,\n",
    "                    phone_number,\n",
    "                    current_organization,\n",
    "                    years_experience,\n",
    "                    skills,\n",
    "                    email,\n",
    "                ),\n",
    "            )\n",
    "        else:\n",
    "            # Perform insert if email does not exist\n",
    "            c = conn.cursor()\n",
    "            c.execute(\n",
    "                \"\"\"INSERT INTO resumes \n",
    "                         (name, email, phone_number, current_organization, years_experience, skills) \n",
    "                         VALUES (?, ?, ?, ?, ?, ?)\"\"\",\n",
    "                (\n",
    "                    name,\n",
    "                    email,\n",
    "                    phone_number,\n",
    "                    current_organization,\n",
    "                    years_experience,\n",
    "                    skills,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "        inferred = {\n",
    "            \"name\": name,\n",
    "            \"email\": email,\n",
    "            \"phone_number\": phone_number,\n",
    "            \"current_organization\": current_organization,\n",
    "            \"years_experience\": years_experience,\n",
    "            \"skills\": skills,\n",
    "        }\n",
    "\n",
    "        return inferred\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Invalid JSON:\", e)\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Function to process multiple PDFs in parallel\n",
    "def process_multiple_pdfs(pdf_paths, model_id, prompt, db_path):\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=None) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                resume_extraction_and_insert, pdf_path, model_id, prompt, db_path\n",
    "            )\n",
    "            for pdf_path in pdf_paths\n",
    "        ]\n",
    "        for future in as_completed(futures):\n",
    "            results.append(future.result())\n",
    "    return results\n",
    "\n",
    "\n",
    "# Sample usage\n",
    "pdf_paths = [\n",
    "    \"/Users/charan/VS_Code/EMEA/db-schenker-entity-extraction/src/entity_extraction/Charana_H_U_Resume_2024.pdf\",\n",
    "    \"/Users/charan/VS_Code/EMEA/db-schenker-entity-extraction/src/entity_extraction/s-2.pdf\",\n",
    "]\n",
    "model_id = \"meta-llama/llama-3-70b-instruct\"\n",
    "resume_extraction_prompt_input = \"\"\"[INST] You are an information extraction assistant. Your task is to extract the following information in JSON format:\n",
    "- Name: \"name\"\n",
    "- Email: \"email\"\n",
    "- Phone Number: \"phone_number\"\n",
    "- Current Organization: \"current_organization\"\n",
    "- Years of Experience: \"years_experience\"\n",
    "- Skills: \"skills\"\n",
    "\n",
    "Use this syntax for your response:\n",
    "{{\n",
    "    \"filename\": {filename},\n",
    "    \"name\": \"...\",\n",
    "    \"email\": \"...\",\n",
    "    \"phone_number\": \"...\",\n",
    "    \"current_organization\": \"...\",\n",
    "    \"years_experience\": \"...\",\n",
    "    \"skills\": \"...\"\n",
    "}}\n",
    "\n",
    "\n",
    "Input: {text}\n",
    "\n",
    "Output:\"\"\"\n",
    "\n",
    "db_path = \"resume_data.db\"\n",
    "\n",
    "# Process multiple PDFs in parallel and insert or update into SQLite\n",
    "results = process_multiple_pdfs(\n",
    "    pdf_paths, model_id, resume_extraction_prompt_input, db_path\n",
    ")\n",
    "print(\"Inferred Information for all PDFs:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
